{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "from keras.optimizers import Adam\n",
        "import cv2\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "test_path = 'Dataset/test_set'\n",
        "train_path = 'Dataset/training_set'\n",
        "train=ImageDataGenerator(rescale=1./255,zoom_range=0.2,shear_range=0.2,horizontal_flip=True)\n",
        "test=ImageDataGenerator(rescale=1./255)\n",
        "train_batches = train.flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=300,shuffle=True,color_mode=\"grayscale\")\n",
        "test_batches = test.flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=300, shuffle=True,color_mode=\"grayscale\")\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,1)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(512, (3, 3), padding=\"valid\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation =\"relu\"))\n",
        "model.add(Dense(9,activation =\"softmax\"))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_batches, batch_size=32,validation_data=test_batches,epochs=25)\n",
        "\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "BiJ9CmrpygSC"
      }
    }
  ]
}